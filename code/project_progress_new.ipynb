{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUSTAV ZA DETEKCIJU KARAKTERISTIČNIH TOČAKA LICA\n",
    "Toni Polanec 2023.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import seaborn as sns\n",
    "\n",
    "import random\n",
    "\n",
    "from tqdm.keras import TqdmCallback\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, LeakyReLU, BatchNormalization\n",
    "from keras.initializers import glorot_uniform, he_uniform\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import SGD, Adam\n",
    "import pickle\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analiza podataka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# učitanje slika\n",
    "face_images = np.load('face_images.npz')\n",
    "faces=face_images.get(face_images.files[0]) \n",
    "\n",
    "# oblikovanje polja\n",
    "faces=np.moveaxis(faces,-1,0)\n",
    "faces=faces.reshape(faces.shape[0],faces.shape[1],faces.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ukupno imamo **7049** različitih slika.  \n",
    "Svaka slika je veličine **96x96** piksela. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(faces[1], cmap='gray')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ primjer slike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# čitanje datoteke s karakterističnim točkama lica\n",
    "landmarks = pd.read_csv('facial_keypoints.csv')\n",
    "landmarks.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Korišteni dataset ima sveukupno 15 karakterističnih točaka lica.  \n",
    "U ovom radu koristit ćemo samo 9 točaka, i to:\n",
    "- centar lijevog oka\n",
    "- lijevi rub lijevog oka\n",
    "- desni rub desnog oka\n",
    "\n",
    "- centar desnog oka\n",
    "- lijevi rub desnog oka\n",
    "- desni rub desnog oka\n",
    "  \n",
    "- vrh nosa\n",
    "  \n",
    "- centar gornje usne\n",
    "- centar donje usne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brisanje podataka o obrvama i ustima (osim bottom_lip_center)\n",
    "landmarks = landmarks.drop(['left_eyebrow_inner_end_x', 'left_eyebrow_inner_end_y', 'left_eyebrow_outer_end_x', 'left_eyebrow_outer_end_y', 'right_eyebrow_inner_end_x', 'right_eyebrow_inner_end_y', 'right_eyebrow_outer_end_x', 'right_eyebrow_outer_end_y', 'mouth_left_corner_x', 'mouth_left_corner_y', 'mouth_right_corner_x', 'mouth_right_corner_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Za svaku sliku imamo 18 parametara koji predstavljaju koordinate 9 različitih točaka na licu (x,y).  \n",
    "<br>\n",
    "Zbog nepravilnosti dataseta moramo provjeriti koliko ima nepostojećih vrijednosti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provjera koliko null vrijednosti imamo u svakom stupcu\n",
    "landmarks.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vidimo da ih ima dosta pa ćemo to sanirati u sljedećim koracima."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prikaz tablice korelacije između karakterističnih točaka lica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks_correlation = landmarks.corr()\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "sns.heatmap(landmarks_correlation, cmap=sns.color_palette(\"blend:#A5A6B1,#271286\", as_cmap=True), annot=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po grafu iznad vidimo da imamo korelacije između nekih točaka u datasetu. Npr. *right_eye_center_x* i *right_eye_outer_corner_x* imaju korelaciju od 0.86.  \n",
    "To ćemo iskoristiti da popunimo null vrijednosti u datasetu.  \n",
    "<br>\n",
    "Npr. uz pomoć točke centra oka ćemo izračunati točke vanjskog i unutarnjeg ruba oka.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predprocesiranje podataka"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po analizi podataka dobili smo informaciju da za karakterističnu točku *eye_center* fali samo 13 vrijednosti. Pa umijesto da izmišljam vrijednosti za te točke, odlučio sam ih izbaciti iz dataseta.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_rows = landmarks[['left_eye_center_x', 'left_eye_center_y', 'right_eye_center_x', 'right_eye_center_y']].isnull().any(axis=1)\n",
    "null_indexes = landmarks[empty_rows].index\n",
    "\n",
    "# brisanje slika koje imaju te određene točke s null vrijednostima\n",
    "faces = np.delete(faces, null_indexes, axis=0)\n",
    "landmarks = landmarks.dropna(subset=['left_eye_center_x', 'left_eye_center_y', 'right_eye_center_x', 'right_eye_center_y'], how='any')\n",
    "\n",
    "\n",
    "print(\"landmarks.shape ->\", landmarks.shape)\n",
    "print(\"faces.shape ->\", faces.shape)\n",
    "# provjera koliko null vrijednosti imamo u svakom stupcu\n",
    "landmarks.isnull().sum()\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isto tako za *mouth_center_bottom_lip* fali 33 vrijednosti, pa ćemo i njih izbaciti iz dataseta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_rows = landmarks[['mouth_center_bottom_lip_x', 'mouth_center_bottom_lip_y']].isnull().any(axis=1)\n",
    "null_indexes = landmarks[empty_rows].index\n",
    "\n",
    "# brisanje slika koje imaju te određene točke s null vrijednostima\n",
    "faces = np.delete(faces, null_indexes, axis=0)\n",
    "landmarks = landmarks.dropna(subset=['mouth_center_bottom_lip_x', 'mouth_center_bottom_lip_y'], how='any')\n",
    "\n",
    "print(\"landmarks.shape ->\", landmarks.shape)\n",
    "print(\"faces.shape ->\", faces.shape)\n",
    "# provjera koliko null vrijednosti imamo u svakom stupcu\n",
    "landmarks.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Popunjavanje null vrijednosti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# podjela na skup s null vrijednostima i skup bez null vrijednosti\n",
    "landmarks_null = landmarks[landmarks.isnull().any(axis=1)]\n",
    "landmarks_not_null = landmarks.dropna()\n",
    "\n",
    "print(f\"landmarks_null:{landmarks_null.shape}   landmarks_not_null:{landmarks_not_null.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sad vidimo da imamo točku centra lijevog i desnog oka, pomoću tih koordinata izračunati ćemo koordinate točaka oko oka koje nedostaju.  \n",
    "OČI:   *left_eye_inner_corner left_eye_outer_corner, right_eye_inner_corner right_eye_outer_corner*  \n",
    "\n",
    "Isto tako za usta, imamo točku donjeg centra usne.  \n",
    "USTA:  *mouth_center_top_lip*    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_null_size = landmarks_not_null.shape[0]\n",
    "print(f\"not_null_size: {not_null_size}\")\n",
    "\n",
    "# EYES\n",
    "\n",
    "left_eye_inner_corner_x_avg_diff = (landmarks_not_null['left_eye_inner_corner_x'].values - landmarks_not_null['left_eye_center_x'].values).sum() / not_null_size\n",
    "left_eye_inner_corner_y_avg_diff = (landmarks_not_null['left_eye_inner_corner_y'].values - landmarks_not_null['left_eye_center_y'].values).sum() / not_null_size\n",
    "\n",
    "left_eye_outer_corner_x_avg_diff = (landmarks_not_null['left_eye_outer_corner_x'].values - landmarks_not_null['left_eye_center_x'].values).sum() / not_null_size\n",
    "left_eye_outer_corner_y_avg_diff = (landmarks_not_null['left_eye_outer_corner_y'].values - landmarks_not_null['left_eye_center_y'].values).sum() / not_null_size\n",
    "\n",
    "right_eye_inner_corner_x_avg_diff = (landmarks_not_null['right_eye_inner_corner_x'].values - landmarks_not_null['right_eye_center_x'].values).sum() / not_null_size\n",
    "right_eye_inner_corner_y_avg_diff = (landmarks_not_null['right_eye_inner_corner_y'].values - landmarks_not_null['right_eye_center_y'].values).sum() / not_null_size\n",
    "\n",
    "right_eye_outer_corner_x_avg_diff = (landmarks_not_null['right_eye_outer_corner_x'].values - landmarks_not_null['right_eye_center_x'].values).sum() / not_null_size\n",
    "right_eye_outer_corner_y_avg_diff = (landmarks_not_null['right_eye_outer_corner_y'].values - landmarks_not_null['right_eye_center_y'].values).sum() / not_null_size\n",
    "\n",
    "\n",
    "# MOUTH\n",
    "\n",
    "mouth_center_top_lip_x_avg_diff = (landmarks_not_null['mouth_center_top_lip_x'].values - landmarks_not_null['mouth_center_bottom_lip_x'].values).sum() / not_null_size\n",
    "mouth_center_top_lip_y_avg_diff = (landmarks_not_null['mouth_center_top_lip_y'].values - landmarks_not_null['mouth_center_bottom_lip_y'].values).sum() / not_null_size\n",
    "\n",
    "\n",
    "print(\"\\nRavnamo se po 'Left eye center':\\n\" +\n",
    "    f\"left_eye_inner_corner_x_avg_diff:\\t{left_eye_inner_corner_x_avg_diff}\\n\" +\n",
    "    f\"left_eye_inner_corner_y_avg_diff:\\t{left_eye_inner_corner_y_avg_diff}\\n\" +\n",
    "    f\"left_eye_outer_corner_x_avg_diff:\\t{left_eye_outer_corner_x_avg_diff}\\n\" +\n",
    "    f\"left_eye_outer_corner_y_avg_diff:\\t{left_eye_outer_corner_y_avg_diff}\\n\" +\n",
    "    \"\\nRavnamo se po 'Right eye center':\\n\" +\n",
    "    f\"right_eye_inner_corner_x_avg_diff:\\t{right_eye_inner_corner_x_avg_diff}\\n\" +\n",
    "    f\"right_eye_inner_corner_y_avg_diff:\\t{right_eye_inner_corner_y_avg_diff}\\n\" +\n",
    "    f\"right_eye_outer_corner_x_avg_diff:\\t{right_eye_outer_corner_x_avg_diff}\\n\" +\n",
    "    f\"right_eye_outer_corner_y_avg_diff:\\t{right_eye_outer_corner_y_avg_diff}\\n\" +\n",
    "    \n",
    "    \"\\nRavnamo se po 'Mouth center bottom lip':\\n\" +\n",
    "    f\"mouth_center_top_lip_x_avg_diff:\\t{mouth_center_top_lip_x_avg_diff}\\n\" +\n",
    "    f\"mouth_center_top_lip_y_avg_diff:\\t{mouth_center_top_lip_y_avg_diff}\\n\"\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sad imamo prosječne udaljenosti od poznatih točaka.  \n",
    "Možemo popuniti sve null vrijednosti tako da dodamo ili oduzmemo prosječnu udaljenost od poznate točke."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EYES\n",
    "landmarks['left_eye_inner_corner_x'] = landmarks['left_eye_inner_corner_x'].fillna(landmarks['left_eye_center_x'] + left_eye_inner_corner_x_avg_diff)\n",
    "landmarks['left_eye_inner_corner_y'] = landmarks['left_eye_inner_corner_y'].fillna(landmarks['left_eye_center_y'] + left_eye_inner_corner_y_avg_diff)\n",
    "\n",
    "landmarks['left_eye_outer_corner_x'] = landmarks['left_eye_outer_corner_x'].fillna(landmarks['left_eye_center_x'] + left_eye_outer_corner_x_avg_diff)\n",
    "landmarks['left_eye_outer_corner_y'] = landmarks['left_eye_outer_corner_y'].fillna(landmarks['left_eye_center_y'] + left_eye_outer_corner_y_avg_diff)\n",
    "\n",
    "landmarks['right_eye_inner_corner_x'] = landmarks['right_eye_inner_corner_x'].fillna(landmarks['right_eye_center_x'] + right_eye_inner_corner_x_avg_diff)\n",
    "landmarks['right_eye_inner_corner_y'] = landmarks['right_eye_inner_corner_y'].fillna(landmarks['right_eye_center_y'] + right_eye_inner_corner_y_avg_diff)\n",
    "\n",
    "landmarks['right_eye_outer_corner_x'] = landmarks['right_eye_outer_corner_x'].fillna(landmarks['right_eye_center_x'] + right_eye_outer_corner_x_avg_diff)\n",
    "landmarks['right_eye_outer_corner_y'] = landmarks['right_eye_outer_corner_y'].fillna(landmarks['right_eye_center_y'] + right_eye_outer_corner_y_avg_diff)\n",
    "\n",
    "# MOUTH\n",
    "landmarks['mouth_center_top_lip_x'] = landmarks['mouth_center_top_lip_x'].fillna(landmarks['mouth_center_bottom_lip_x'] + mouth_center_top_lip_x_avg_diff)\n",
    "landmarks['mouth_center_top_lip_y'] = landmarks['mouth_center_top_lip_y'].fillna(landmarks['mouth_center_bottom_lip_y'] + mouth_center_top_lip_y_avg_diff)\n",
    "\n",
    "# Provjera ako sad još uvijek ima null vrijednosti\n",
    "landmarks.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Afina transformacije"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = np.array(landmarks)\n",
    "print(landmarks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin, cos, pi\n",
    "import cv2\n",
    "\n",
    "sample = 50\n",
    "\n",
    "rotation_angles = [12]    # Rotation angle in degrees (includes both clockwise & anti-clockwise rotations)\n",
    "\n",
    "#Function for Rotation of the Images\n",
    "def rotate(images, keypoints):\n",
    "    rotated_images = []\n",
    "    rotated_keypoints = []\n",
    "    print(\"Augmenting for angles (in degrees): \")\n",
    "    \n",
    "    for angle in rotation_angles:    # Rotation augmentation for a list of angle values\n",
    "        for angle in [angle,-angle]:\n",
    "            print(f'{angle}', end='  ')\n",
    "            M = cv2.getRotationMatrix2D((48,48), angle, 1.0)\n",
    "            angle_rad = -angle*pi/180.     # Obtain angle in radians from angle in degrees (notice negative sign for change in clockwise vs anti-clockwise directions from conventional rotation to cv2's image rotation)\n",
    "            \n",
    "            # For train_images\n",
    "            for image in images:\n",
    "                rotated_image = cv2.warpAffine(image, M, (96,96), flags=cv2.INTER_CUBIC)\n",
    "                rotated_images.append(rotated_image)\n",
    "            \n",
    "            # For train_keypoints\n",
    "            for keypoint in keypoints:\n",
    "                rotated_keypoint = keypoint - 48.    # Subtract the middle value of the image dimension\n",
    "                for idx in range(0,len(rotated_keypoint),2):\n",
    "                    # https://in.mathworks.com/matlabcentral/answers/93554-how-can-i-rotate-a-set-of-points-in-a-plane-by-a-certain-angle-about-an-arbitrary-point\n",
    "                    rotated_keypoint[idx] = rotated_keypoint[idx]*cos(angle_rad)-rotated_keypoint[idx+1]*sin(angle_rad)\n",
    "                    rotated_keypoint[idx+1] = rotated_keypoint[idx]*sin(angle_rad)+rotated_keypoint[idx+1]*cos(angle_rad)\n",
    "                rotated_keypoint += 48.   # Add the earlier subtracted value\n",
    "                rotated_keypoints.append(rotated_keypoint)\n",
    "            \n",
    "    return np.reshape(rotated_images,(-1,96,96,1)), rotated_keypoints\n",
    "\n",
    "#For more details on the transformation of the images below is the link.\n",
    "#https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_geometric_transformations/py_geometric_transformations.html\n",
    "\n",
    "if True:\n",
    "    db_images_rotated, df_keypoints_rotated = rotate(faces, landmarks)\n",
    "    print(\"\\nShape of rotated_images:\",np.shape(db_images_rotated))\n",
    "    print(\"Shape of rotated_keypoints:\\n\",np.shape(df_keypoints_rotated))\n",
    "    \n",
    "    #Concatenating the train images with rotated image & train keypoints with rotated train points\n",
    "    faces = np.concatenate((faces, db_images_rotated))\n",
    "    landmarks = np.concatenate((landmarks, df_keypoints_rotated))\n",
    "    fig, axis = plt.subplots()\n",
    "    #plot_image(db_images_rotated[sample], df_keypoints_rotated[sample], axis, \"Rotation Augmentation\")\n",
    "    \n",
    "print(\"Shape of images database after shifting:\",np.shape(faces))\n",
    "print(\"Shape of keypoints dataframe after shifting:\",np.shape(landmarks))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vizualizacija podataka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/satyaprakash13820/facial-landmark?scriptVersionId=76260280&cellId=13\n",
    "\n",
    "\n",
    "print(f\"faces.shape -> {faces.shape}\")\n",
    "landmark_len = len(landmarks)\n",
    "print(f\"key_feature_num -> {landmark_len}\\n\")\n",
    "\n",
    "faces = faces/255 # Normalizacija\n",
    "\n",
    "#landmarks.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"normalized_faces.shape -> {faces.shape}\")\n",
    "print(faces)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(image_array, landmarks, index):\n",
    "    plt.imshow(image_array[index], cmap='gray')\n",
    "    plt.scatter(landmarks[index][0::2], landmarks[index][1::2], c=\"#0f0\", marker='P')\n",
    "    # plt.scatter(landmarks.iloc[index,0::2], landmarks.iloc[index,1::2], c=\"#0f0\", marker='P')\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    print(index)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image(faces, landmarks, random.randint(0,21000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image(faces, landmarks, 5699)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neke točke nisu najpreciznije označene, ali to je nedostatak izračunavanja nedostajućih vrijednosti u datasetu i sa tim ćemo morati živjeti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mult_images(image_array, landmarks, rows = 3, cols = 3):\n",
    "    default_pics = [random.randint(0,21000) for i in range(rows*cols)]\n",
    "    pic_size = 96\n",
    "    index = 0\n",
    "\n",
    "    fig, ax = plt.subplots(rows,cols,sharex=True,sharey=True,figsize=[cols*2,rows*2])\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            ax[row,col].imshow(image_array[default_pics[index]], cmap='gray')\n",
    "            ax[row,col].scatter(landmarks[default_pics[index]][0::2], landmarks[default_pics[index]][1::2], c=\"#0f0\", marker='+')\n",
    "            # ax[row,col].scatter(landmarks.iloc[default_pics[index],0::2], landmarks.iloc[default_pics[index],1::2], c=\"#0f0\", marker='+')\n",
    "            ax[row,col].set_xticks(())\n",
    "            ax[row,col].set_yticks(())\n",
    "            ax[row,col].set_title('image index = %d' %(default_pics[index]),fontsize=10)\n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mult_images(faces, landmarks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Priprema podataka za treniranje modela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"faces.shape     -> {faces.shape}\")\n",
    "print(f\"landmarks.shape -> {landmarks.shape}\")\n",
    "train_x,test_x,train_y,test_y = train_test_split(faces, landmarks, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\ntrain_x.shape -> {train_x.shape}\")\n",
    "print(f\"train_y.shape -> {train_y.shape}\")\n",
    "print(f\"test_x.shape  -> {test_x.shape}\")\n",
    "print(f\"test_y.shape  -> {test_y.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size=96\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Input(shape=(img_size, img_size, 1)))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3,3), padding=\"same\"))#, kernel_initializer=he_uniform()))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3), padding=\"same\"))#, kernel_initializer=he_uniform()))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3,3), padding=\"same\"))#, kernel_initializer=he_uniform()))\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(256, kernel_initializer=he_uniform(), activation=LeakyReLU(0.1)))\n",
    "model.add(Dense(128, activation=LeakyReLU(0.1)))\n",
    "model.add(Dropout(0.1))\n",
    "# # model.add(Dense(64, kernel_initializer=he_uniform(), activation=LeakyReLU(0.1)))\n",
    "# model.add(Dense(64, activation=LeakyReLU(0.1)))\n",
    "# model.add(LeakyReLU(alpha=0))\n",
    "model.add(Dense(18))#,kernel_initializer=he_uniform()))\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.001), metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()                      "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "\n",
    "# visualkeras.layered_view(model, to_file='model_300epochs_128batch_visualisation.png', legend=True).show() # write and show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "import pydot\n",
    "\n",
    "# tf.keras.utils.plot_model(\n",
    "#     model,\n",
    "#     to_file=\"model_300_128_visualisation2.png\",\n",
    "#     show_shapes=True,\n",
    "#     show_dtype=False,\n",
    "#     show_layer_names=True,\n",
    "#     rankdir=\"TB\",\n",
    "#     expand_nested=True,\n",
    "#     dpi=96,\n",
    "#     layer_range=None,\n",
    "#     show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ann_visualizer.visualize import ann_viz\n",
    "\n",
    "# ann_viz(model, \n",
    "#     view=True, \n",
    "#     filename=\"model_300_128_visualisation3.png\", \n",
    "#     title=\"Model visualisation\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treniranje modela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit(\n",
    "    x = train_x, \n",
    "    y = train_y,\n",
    "    batch_size = 100,\n",
    "    epochs = 60,\n",
    "    validation_data = (test_x, test_y))\n",
    "\n",
    "\n",
    "model.save('model_temp.h5')\n",
    "with open('history_temp', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('model.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('model_300epochs_128batch.h5')\n",
    "model = load_model('model_300epochs_128batch.h5')\n",
    "with open('history_60_128_goodgraph', 'rb') as file_pi:\n",
    "    history = pickle.load(file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = history.history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_x, test_y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Možemo prikazati graf smanjenja greške predikcije kroz epohe.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# history_dict = json.load(open('model_history_temp.json', 'r'))\n",
    "\n",
    "\n",
    "plt.figure(figsize=[10,6])\n",
    "plt.plot(history['loss'],'b',linewidth=2.0)\n",
    "plt.plot(history['val_loss'],'r',linewidth=2.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'], fontsize=14)\n",
    "plt.ylim(0, 500)\n",
    "plt.xlabel('Epochs ',fontsize=14)\n",
    "plt.ylabel('Loss',fontsize=14)\n",
    "plt.title('Loss Curves',fontsize=14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predicted_image(images, truth, prediction, index):\n",
    "    print(index, \"->\" , prediction[index])\n",
    "    plt.imshow(images[index], cmap='gray')\n",
    "    plt.scatter(truth.iloc[index, 0::2], truth.iloc[index, 1::2], c=\"#0f0\", marker='P')\n",
    "    plt.scatter(prediction[index, 0::2], prediction[index, 1::2], c=\"#f00\", marker='P')\n",
    "    plt.legend([\"Truth\",\"Prediction\"])\n",
    "    plt.show()\n",
    "\n",
    "def plot_predicted_images(images, truth, prediction, with_truth=False, random_indexes=True):\n",
    "    prediction_no_truth = [851, 866, 142, 1241, 1171, 651, 1376, 89, 139]\n",
    "    prediciton_truth = [73, 501, 277, 189, 644, 268, 679, 864, 452]\n",
    "\n",
    "    if random_indexes:\n",
    "        indexes = [random.randint(0, len(test_x))-1 for i in range(9)]\n",
    "    else:\n",
    "        if with_truth:\n",
    "            indexes = prediciton_truth\n",
    "        else:\n",
    "            indexes = prediction_no_truth\n",
    "\n",
    "    rows = 3\n",
    "    cols = 3\n",
    "\n",
    "    arr_i = 0\n",
    "    fig, ax = plt.subplots(rows,cols,sharex=True,sharey=True,figsize=[cols*2,rows*2])\n",
    "    for row in range(rows):\n",
    "        for col in range(cols):\n",
    "            index = indexes[arr_i]\n",
    "            ax[row,col].imshow(images[index], cmap='gray')\n",
    "            if with_truth:\n",
    "                ax[row,col].scatter(truth.iloc[index, 0::2], truth.iloc[index, 1::2], c=\"#0f0\", marker='+')\n",
    "            ax[row,col].scatter(prediction[index, 0::2], prediction[index, 1::2], c=\"#f00\", marker='+')\n",
    "            # ax[row,col].set_xticks(())\n",
    "            # ax[row,col].set_yticks(())\n",
    "            ax[row,col].set_title('image index = %d' %(index),fontsize=10)\n",
    "            arr_i += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usporedimo predicted sliku s originalnom slikom.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predicted_image(test_x, test_y, y_pred, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predicted_images(test_x, test_y, y_pred, with_truth=False, random_indexes=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
